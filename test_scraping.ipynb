{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting raw html data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "import pymongo\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "LEETCODE_BASE_URL= \"https://leetcode.com/problems\"\n",
    "\n",
    "def get_html(problem_name):\n",
    "  # leetcode url \n",
    "  url = f\"{LEETCODE_BASE_URL}/{problem_name}/\"\n",
    "\n",
    "  # Make a GET request to the website\n",
    "  response = requests.get(url)\n",
    "\n",
    "  # Parse the HTML content\n",
    "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "  problem_description = soup.find(\"script\", id=\"__NEXT_DATA__\")\n",
    "  html = None\n",
    "  if problem_description:\n",
    "    # contains all of the script tag, e.g. \"jQuery(window)...\"\n",
    "    contents = problem_description.string\n",
    "    \n",
    "    # convert to a dictionary\n",
    "    dict_contents = json.loads(str(contents))\n",
    "\n",
    "    # drilling into the object \n",
    "    lst_of_objects = dict_contents['props']['pageProps']['dehydratedState']['queries']\n",
    "    \n",
    "    # filtering the list of objects\n",
    "    result = [obj for obj in lst_of_objects if ('question' in obj['state']['data'] and \n",
    "                                                'content' in obj['state']['data']['question'] and \n",
    "                                                obj['state']['data']['question']['content'] is not None)]\n",
    "    \n",
    "    if len(result) > 0: \n",
    "      # drilling further into the object to find the html content\n",
    "      html = result[0]['state']['data']['question']['content']\n",
    "  return response, html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Python & Javascript code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_snippets(problem_name):\n",
    "  # we dont care about the particular question\n",
    "  url = f\"{LEETCODE_BASE_URL}/{problem_name}/\"\n",
    "    \n",
    "  # Make a GET request to the website\n",
    "  response = requests.get(url)\n",
    "\n",
    "  # Parse the HTML content\n",
    "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "  \n",
    "  problem_description = soup.find(\"script\", id=\"__NEXT_DATA__\")\n",
    "\n",
    "  code_snippets = None\n",
    "  if problem_description:\n",
    "    # contains all of the script tag, e.g. \"jQuery(window)...\"\n",
    "    contents = problem_description.string\n",
    "    dict_contents = json.loads(str(contents))\n",
    "    \n",
    "\n",
    "    list_of_starter_codes = (dict_contents['props']['pageProps']['dehydratedState']['queries'][2]['state']\n",
    "                            ['data']['question']['codeSnippets'])\n",
    "\n",
    "    if list_of_starter_codes is not None:\n",
    "\n",
    "      code_snippets = [obj for obj in list_of_starter_codes if (obj['lang'] == 'Python3' or obj['lang'] == 'JavaScript')]\n",
    "\n",
    "      return code_snippets\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting problem explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_problem_description(html):\n",
    "  if html is not None:\n",
    "    result = re.match(r\"(.+?)<strong class=.example.\", html, re.DOTALL).group(1)\n",
    "\n",
    "    soup = BeautifulSoup(result, 'html.parser')\n",
    "\n",
    "    # Extract all text from the HTML and remove the tags\n",
    "    text = soup.get_text()\n",
    "\n",
    "    return text\n",
    "  return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(html):\n",
    "  if html is not None:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find all elements with the class \"example\"\n",
    "    examples = soup.find_all(class_=\"example\")\n",
    "\n",
    "    result = []\n",
    "    for example in examples:\n",
    "        # Find the next sibling element (pre element in this case)\n",
    "        pre_element = example.findNext(\"pre\")\n",
    "        # Get the text from the pre element\n",
    "        example_text = pre_element.text\n",
    "        result.append(example_text)\n",
    "\n",
    "    return result\n",
    "  return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constraints(html):\n",
    "    if html is not None:\n",
    "        constraints = re.search(r\"<p><strong>Constraints:</strong></p>(.*)\", html, re.DOTALL)\n",
    "        if constraints:\n",
    "            constraints = constraints.group(1)\n",
    "            soup = BeautifulSoup(constraints, 'html.parser')\n",
    "            text = soup.get_text()\n",
    "            return text\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting problem names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "\"Contains Duplicate\",\n",
    "\"Valid Anagram\",\n",
    "\"Two Sum\",\n",
    "\"Group Anagrams\",\n",
    "\"Top K Frequent Elements\",\n",
    "\"Product of Array Except Self\",\n",
    "\"Valid Sudoku\",\n",
    "\"Encode And Decode Strings\",\t\n",
    "\"Longest Consecutive Sequence\",\n",
    "\"Valid Palindrome\",\n",
    "\"Two Sum II Input Array Is Sorted\",\n",
    "\"3Sum\",\n",
    "\"Container With Most Water\",\n",
    "\"Trapping Rain Water\",\n",
    "\"Best Time to Buy And Sell Stock\",\n",
    "\"Longest Substring Without Repeating Characters\",\n",
    "\"Longest Repeating Character Replacement\",\n",
    "\"Permutation In String\",\n",
    "\"Minimum Window Substring\",\n",
    "\"Sliding Window Maximum\",\n",
    "\"Valid Parentheses\",\n",
    "\"Min Stack\",\n",
    "\"Evaluate Reverse Polish Notation\",\n",
    "\"Generate Parentheses\",\n",
    "\"Daily Temperatures\",\n",
    "\"Car Fleet\",\n",
    "\"Largest Rectangle In Histogram\",\n",
    "\"Binary Search\",\n",
    "\"Search a 2D Matrix\",\n",
    "\"Koko Eating Bananas\",\n",
    "\"Find Minimum In Rotated Sorted Array\",\n",
    "\"Search In Rotated Sorted Array\",\n",
    "\"Time Based Key Value Store\",\n",
    "\"Median of Two Sorted Arrays\",\n",
    "\"Reverse Linked List\",\n",
    "\"Merge Two Sorted Lists\",\n",
    "\"Reorder List\",\n",
    "\"Remove Nth Node From End of List\",\n",
    "\"Copy List With Random Pointer\",\n",
    "\"Add Two Numbers\",\n",
    "\"Linked List Cycle\",\n",
    "\"Find The Duplicate Number\",\n",
    "\"LRU Cache\",\n",
    "\"Merge K Sorted Lists\",\n",
    "\"Reverse Nodes In K Group\",\n",
    "\"Invert Binary Tree\",\n",
    "\"Maximum Depth of Binary Tree\",\n",
    "\"Diameter of Binary Tree\",\n",
    "\"Balanced Binary Tree\",\n",
    "\"Same Tree\",\n",
    "\"Subtree of Another Tree\",\n",
    "\"Lowest Common Ancestor of a Binary Search Tree\",\n",
    "\"Binary Tree Level Order Traversal\",\n",
    "\"Binary Tree Right Side View\",\n",
    "\"Count Good Nodes In Binary Tree\",\n",
    "\"Validate Binary Search Tree\",\n",
    "\"Kth Smallest Element In a Bst\",\n",
    "\"Construct Binary Tree From Preorder And Inorder Traversal\",\n",
    "\"Binary Tree Maximum Path Sum\",\n",
    "\"Serialize And Deserialize Binary Tree\",\n",
    "\"Implement Trie Prefix Tree\",\n",
    "\"Design Add And Search Words Data Structure\",\n",
    "\"Word Search II\",\n",
    "\"Kth Largest Element In a Stream\",\n",
    "\"Last Stone Weight\",\n",
    "\"K Closest Points to Origin\",\n",
    "\"Kth Largest Element In An Array\",\n",
    "\"Task Scheduler,\", \n",
    "\"Design Twitter,\", \n",
    "\"Find Median From Data Stream,\",\n",
    "\"Subsets,\", \n",
    "\"Combination Sum,\", \n",
    "\"Permutations,\", \n",
    "\"Subsets II,\", \n",
    "\"Combination Sum II,\", \n",
    "\"Word Search,\", \n",
    "\"Palindrome Partitioning,\", \n",
    "\"Letter Combinations of a Phone Number,\", \n",
    "\"N Queens,\", \n",
    "\"Number of Islands,\", \n",
    "\"Clone Graph,\", \n",
    "\"Max Area of Island,\", \n",
    "\"Pacific Atlantic Water Flow,\", \n",
    "\"Surrounded Regions,\", \n",
    "\"Rotting Oranges,\", \n",
    "\"Walls And Gates,\", \n",
    "\"Course Schedule,\", \n",
    "\"Course Schedule II,\", \n",
    "\"Redundant Connection,\", \n",
    "\"Number of Connected Components In An Undirected Graph,\", \n",
    "\"Graph Valid Tree,\", \n",
    "\"Word Ladder,\", \n",
    "\"Reconstruct Itinerary,\", \n",
    "\"Min Cost to Connect All Points,\", \n",
    "\"Network Delay Time,\", \n",
    "\"Swim In Rising Water,\", \n",
    "\"Alien Dictionary,\",\n",
    "\"Cheapest Flights Within K Stops,\", \n",
    "\"Climbing Stairs,\", \n",
    "\"Min Cost Climbing Stairs,\", \n",
    "\"House Robber,\", \n",
    "\"House Robber II,\", \n",
    "\"Longest Palindromic Substring,\", \n",
    "\"Palindromic Substrings,\", \n",
    "\"Decode Ways,\", \n",
    "\"Coin Change,\", \n",
    "\"Maximum Product Subarray,\", \n",
    "\"Word Break,\", \n",
    "\"Longest Increasing Subsequence,\", \n",
    "\"Partition Equal Subset Sum,\", \n",
    "\"Unique Paths,\", \n",
    "\"Longest Common Subsequence,\", \n",
    "\"Best Time to Buy And Sell Stock With Cooldown,\", \n",
    "\"Coin Change II,\", \"Target Sum,\", \n",
    "\"Interleaving String,\", \n",
    "\"Longest Increasing Path In a Matrix,\", \n",
    "\"Distinct Subsequences,\", \n",
    "\"Edit Distance,\", \n",
    "\"Burst Balloons,\", \n",
    "\"Regular Expression Matching,\", \n",
    "\"Maximum Subarray,\", \n",
    "\"Jump Game,\", \n",
    "\"Jump Game II,\", \n",
    "\"Gas Station,\", \n",
    "\"Hand of Straights,\",\n",
    "\"Merge Triplets to Form Target Triplet,\", \n",
    "\"Partition Labels,\", \n",
    "\"Valid Parenthesis String,\", \n",
    "\"Insert Interval,\", \n",
    "\"Merge Intervals,\", \n",
    "\"Non Overlapping Intervals,\", \n",
    "\"Meeting Rooms,\", \n",
    "\"Meeting Rooms II,\", \n",
    "\"Minimum Interval to Include Each Query,\", \n",
    "\"Rotate Image,\", \n",
    "\"Spiral Matrix,\", \n",
    "\"Set Matrix Zeroes,\", \n",
    "\"Happy Number,\", \n",
    "\"Plus One,\", \n",
    "\"Powx n\", \n",
    "\"Multiply Strings,\", \n",
    "\"Detect Squares,\", \n",
    "\"Single Number,\", \n",
    "\"Number of 1 Bits,\", \n",
    "\"Counting Bits,\", \n",
    "\"Reverse Bits,\", \n",
    "\"Missing Number,\", \n",
    "\"Sum of Two Integers,\", \n",
    "\"Reverse Integer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_kebab_case(s):\n",
    "    # Replace any non-alphanumeric characters with hyphens\n",
    "    s = re.sub(r'[^a-zA-Z0-9]', '-', s).strip(\"-\")\n",
    "    # Convert to lowercase\n",
    "    s = s.lower()\n",
    "    return s\n",
    "\n",
    "kebab_names = [to_kebab_case(name) for name in names]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kokolearn-admin KokoLearn123...\n",
      "Could not parse Lowest Common Ancestor of a Binary Search Tree\n",
      "Could not parse Binary Tree Level Order Traversal\n",
      "Could not parse Binary Tree Right Side View\n",
      "Could not parse Count Good Nodes In Binary Tree\n",
      "Could not parse Validate Binary Search Tree\n",
      "Could not parse Kth Smallest Element In a Bst\n",
      "Could not parse Construct Binary Tree From Preorder And Inorder Traversal\n",
      "Could not parse Binary Tree Maximum Path Sum\n",
      "Could not parse Serialize And Deserialize Binary Tree\n",
      "Could not parse Implement Trie Prefix Tree\n",
      "Could not parse Design Add And Search Words Data Structure\n",
      "Could not parse Word Search II\n",
      "Could not parse Kth Largest Element In a Stream\n",
      "Could not parse Last Stone Weight\n",
      "Could not parse K Closest Points to Origin\n",
      "Could not parse Kth Largest Element In An Array\n",
      "Could not parse Task Scheduler,\n",
      "Could not parse Design Twitter,\n",
      "Could not parse Find Median From Data Stream,\n",
      "Could not parse Subsets,\n",
      "Could not parse Combination Sum,\n",
      "Could not parse Permutations,\n",
      "Could not parse Subsets II,\n",
      "Could not parse Combination Sum II,\n",
      "Could not parse Word Search,\n",
      "Could not parse Palindrome Partitioning,\n",
      "Could not parse Letter Combinations of a Phone Number,\n",
      "Could not parse N Queens,\n",
      "Could not parse Number of Islands,\n",
      "Could not parse Clone Graph,\n",
      "Could not parse Max Area of Island,\n",
      "Could not parse Pacific Atlantic Water Flow,\n",
      "Could not parse Surrounded Regions,\n",
      "Could not parse Rotting Oranges,\n",
      "Could not parse Walls And Gates,\n",
      "Could not parse Course Schedule,\n",
      "Could not parse Course Schedule II,\n",
      "Could not parse Redundant Connection,\n",
      "Could not parse Number of Connected Components In An Undirected Graph,\n",
      "Could not parse Graph Valid Tree,\n",
      "Could not parse Word Ladder,\n",
      "Could not parse Reconstruct Itinerary,\n",
      "Could not parse Min Cost to Connect All Points,\n",
      "Could not parse Network Delay Time,\n",
      "Could not parse Swim In Rising Water,\n",
      "Could not parse Alien Dictionary,\n",
      "Could not parse Cheapest Flights Within K Stops,\n",
      "Could not parse Climbing Stairs,\n",
      "Could not parse Min Cost Climbing Stairs,\n",
      "Could not parse House Robber,\n",
      "Could not parse House Robber II,\n",
      "Could not parse Longest Palindromic Substring,\n",
      "Could not parse Palindromic Substrings,\n",
      "Could not parse Decode Ways,\n",
      "Could not parse Coin Change,\n",
      "Could not parse Maximum Product Subarray,\n",
      "Could not parse Word Break,\n",
      "Could not parse Longest Increasing Subsequence,\n",
      "Could not parse Plus One,\n",
      "Could not parse Powx n\n",
      "Could not parse Multiply Strings,\n",
      "Could not parse Detect Squares,\n",
      "Could not parse Single Number,\n",
      "Could not parse Number of 1 Bits,\n",
      "Could not parse Counting Bits,\n",
      "Could not parse Reverse Bits,\n",
      "Could not parse Missing Number,\n",
      "Could not parse Sum of Two Integers,\n",
      "Could not parse Reverse Integer\n"
     ]
    }
   ],
   "source": [
    "MONGO_USER = os.environ['MONGO_USER']\n",
    "MONGO_PASSWORD  = os.environ['MONGO_PASSWORD']\n",
    "print(MONGO_USER, MONGO_PASSWORD )\n",
    "MONGO_BASE_URL = f\"mongodb+srv://{MONGO_USER}:{MONGO_PASSWORD}@cluster0.pn9un82.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# Connect to the server\n",
    "client = pymongo.MongoClient(MONGO_BASE_URL)\n",
    "\n",
    "# Get a reference to a database\n",
    "db = client['kokolearn']\n",
    "\n",
    "# Get a reference to a collection\n",
    "collection = db['questions']\n",
    "\n",
    "for kebab_name, name in zip(kebab_names, names):\n",
    "  response, html = get_html(kebab_name)\n",
    "  if response.status_code == 200:\n",
    "    description = get_problem_description(html)\n",
    "    examples = get_examples(html)\n",
    "    constraint = get_constraints(html)\n",
    "    code_snippets = get_code_snippets(kebab_name)\n",
    "    #TODO: \n",
    "      # 1) get name \n",
    "      # 2) get description \n",
    "      # 3) get examples \n",
    "      # 4) get constraint\n",
    "      # 5) get code snippets\n",
    "    document = {\n",
    "      \"name\": name,\n",
    "      \"description\": description,\n",
    "      \"examples\": examples,\n",
    "      \"constraint\": constraint,\n",
    "      \"code_snippets\": code_snippets\n",
    "    }\n",
    "    collection.insert_one(document)\n",
    "  else: \n",
    "    print(f\"Could not parse {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ec1d081f4f13b1ff9a322e10bdfcb11cc65b7860a561386add35709c62a8d31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
