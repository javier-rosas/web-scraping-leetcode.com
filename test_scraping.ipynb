{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting raw html data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "import pymongo\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "LEETCODE_BASE_URL= \"https://leetcode.com/problems\"\n",
    "\n",
    "def get_html(problem_name):\n",
    "  # leetcode url \n",
    "  url = f\"{LEETCODE_BASE_URL}/{problem_name}/\"\n",
    "\n",
    "  # Make a GET request to the website\n",
    "  response = requests.get(url)\n",
    "\n",
    "  # Parse the HTML content\n",
    "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "  problem_description = soup.find(\"script\", id=\"__NEXT_DATA__\")\n",
    "  html = None\n",
    "  if problem_description:\n",
    "    # contains all of the script tag, e.g. \"jQuery(window)...\"\n",
    "    contents = problem_description.string\n",
    "    \n",
    "    # convert to a dictionary\n",
    "    dict_contents = json.loads(str(contents))\n",
    "\n",
    "    # drilling into the object \n",
    "    lst_of_objects = dict_contents['props']['pageProps']['dehydratedState']['queries']\n",
    "    \n",
    "    # filtering the list of objects\n",
    "    result = [obj for obj in lst_of_objects if ('question' in obj['state']['data'] and \n",
    "                                                'content' in obj['state']['data']['question'] and \n",
    "                                                obj['state']['data']['question']['content'] is not None)]\n",
    "    \n",
    "    if len(result) > 0: \n",
    "      # drilling further into the object to find the html content\n",
    "      html = result[0]['state']['data']['question']['content']\n",
    "  \n",
    "  return response, html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Python & Javascript code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_snippets(problem_name):\n",
    "  # we dont care about the particular question\n",
    "  url = f\"{LEETCODE_BASE_URL}/{problem_name}/\"\n",
    "    \n",
    "  # Make a GET request to the website\n",
    "  response = requests.get(url)\n",
    "\n",
    "  # Parse the HTML content\n",
    "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "  \n",
    "  problem_description = soup.find(\"script\", id=\"__NEXT_DATA__\")\n",
    "\n",
    "  code_snippets = None\n",
    "  if problem_description:\n",
    "    # contains all of the script tag, e.g. \"jQuery(window)...\"\n",
    "    contents = problem_description.string\n",
    "    \n",
    "    dict_contents = json.loads(str(contents))\n",
    "    \n",
    "    list_of_starter_codes = (dict_contents['props']['pageProps']['dehydratedState']['queries'][2]['state']\n",
    "                            ['data']['question']['codeSnippets'])\n",
    "\n",
    "    if list_of_starter_codes is not None:\n",
    "\n",
    "      code_snippets = [obj for obj in list_of_starter_codes if (obj['lang'] == 'Python3' or obj['lang'] == 'JavaScript')]\n",
    "\n",
    "      return code_snippets\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting problem explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_problem_description(html):\n",
    "  if html is not None:\n",
    "    # regex matches everything before the first example\n",
    "    result = re.match(r\"(.+?)<strong class=.example.\", html, re.DOTALL).group(1)\n",
    "\n",
    "    soup = BeautifulSoup(result, 'html.parser')\n",
    "\n",
    "    # Extract all text from the HTML and remove the tags\n",
    "    text = soup.get_text()\n",
    "    # Find the element containing the image\n",
    "    \n",
    "    image_element = soup.find('img')\n",
    "\n",
    "    image_src = None\n",
    "    if image_element is not None: \n",
    "      # Extract the image source\n",
    "      image_src = image_element['src']\n",
    "\n",
    "    return {\"description_text\": text, \"description_img_source\": image_src}\n",
    "  return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(html):\n",
    "  if html is not None:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find all elements with the class \"example\"\n",
    "    examples = soup.find_all(class_=\"example\")\n",
    "\n",
    "    result = []\n",
    "    for example in examples:\n",
    "        # Find the next sibling element (pre element in this case)\n",
    "        pre_element = example.findNext(\"pre\")\n",
    "        # Get the text from the pre element\n",
    "        example_text = pre_element.text\n",
    "        # get image \n",
    "        image_element = example.findNext('img')\n",
    "        img_src = None\n",
    "        if image_element is not None: \n",
    "          # Extract the image source\n",
    "          img_src = image_element['src']\n",
    "\n",
    "        result.append({\"example_text\": example_text, \"example_img_source\": img_src})\n",
    "\n",
    "    return result\n",
    "  return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constraints(html):\n",
    "    if html is not None:\n",
    "        constraints = re.search(r\"<p><strong>Constraints:</strong></p>(.*)\", html, re.DOTALL)\n",
    "        if constraints:\n",
    "            constraints = constraints.group(1)\n",
    "            soup = BeautifulSoup(constraints, 'html.parser')\n",
    "            text = soup.get_text()\n",
    "            return text\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, htm = get_html(\"count-and-say\")\n",
    "examples = get_examples(htm)\n",
    "descrip, img_url = get_problem_description(htm)\n",
    "print(img_url)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding kebab-case field to every document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "\n",
    "def camel_case(s):\n",
    "  s = re.sub(r\"(_|-)+\", \" \", s).title().replace(\" \", \"\")\n",
    "  return ''.join([s[0].lower(), s[1:]])\n",
    "\n",
    "MONGO_USER = os.environ['MONGO_USER']\n",
    "MONGO_PASSWORD  = os.environ['MONGO_PASSWORD']\n",
    "MONGO_BASE_URL = f\"mongodb+srv://{MONGO_USER}:{MONGO_PASSWORD}@cluster0.pn9un82.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# Connect to the server\n",
    "client = pymongo.MongoClient(MONGO_BASE_URL)\n",
    "\n",
    "# Get a reference to a database\n",
    "db = client['kokolearn']\n",
    "\n",
    "# Get a reference to a collection\n",
    "collection = db['questions']\n",
    "\n",
    "# Specify the projection to include only the name field\n",
    "projection = {\"name\": 1}\n",
    "\n",
    "# Find all documents in the collection\n",
    "cursor = collection.find({}, projection)\n",
    "\n",
    "lst = []\n",
    "# Iterate through the documents and print the names\n",
    "for document in cursor:\n",
    "  lst.append(document[\"name\"])\n",
    "\n",
    "for name in lst: \n",
    "  # Define the filter to select the document to update\n",
    "  filter = {\"name\": name}\n",
    "\n",
    "  # Define the update operation\n",
    "  update = { \"$set\": {\"kebab_case\": camel_case(name)} }\n",
    "\n",
    "  # Update the document\n",
    "  result = collection.update_one(filter, update)\n",
    "\n",
    "  # Print the number of updated documents\n",
    "  print(result.modified_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x1097e7a00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update all documents in the collection\n",
    "collection.update_many({}, {\"$rename\": {\"kebab_case\": \"camelCaseName\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ec1d081f4f13b1ff9a322e10bdfcb11cc65b7860a561386add35709c62a8d31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
